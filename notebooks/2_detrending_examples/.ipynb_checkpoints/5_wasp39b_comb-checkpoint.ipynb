{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988b5848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exoclock: Checking ephemerides database...\n",
      "exoclock: Checking catalogues database...\n",
      "exoclock: Checking ut database...\n",
      "pylightcurve: Checking exotethys database...\n",
      "pylightcurve: Checking photometry database...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pylightcurve as plc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "##### Create a Planet object\n",
    "###############################################################################################\n",
    "\n",
    "# At first we need to  create a Planet object.\n",
    "# Planets include in the ExoClock project (https://www.exoclock.space/database/planets)\n",
    "# can be loaded automatically. \n",
    "# Alteranatively we can difine our custom Planet object (see notebook: The Planet class)\n",
    "\n",
    "planet = plc.get_planet('WASP-39b')\n",
    "\n",
    "###############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d0615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "##### Load data\n",
    "###############################################################################################\n",
    "\n",
    "# Here we will combine all the data for WASP-39b from the previous notebooks.\n",
    "\n",
    "data_ground = plc.open_dict('wasp39b_ground.pickle')\n",
    "data_tess = plc.open_dict('wasp39b_tess.pickle')\n",
    "data_hst = plc.open_dict('wasp39b_hst.pickle')\n",
    "data_jwst = plc.open_dict('wasp39b_jwst.pickle')\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "##### Define the trend function\n",
    "###############################################################################################\n",
    "\n",
    "# Here we will combine all the trend function from the previous notebooks.\n",
    "\n",
    "# Keep the default second order polynomial with time for JWST and TESS data.\n",
    "\n",
    "# A fisrt order polynomial with airmass for the ground-based data:\n",
    "\n",
    "data_ground['detrending_series'] = 'airmass'\n",
    "data_ground['detrending_order'] = 1\n",
    "\n",
    "\n",
    "# A linear with time in the observation (time - start of the observation) \n",
    "# and an exponential with orbital phase of HST (ophase in the auxiliary data) for the HST data.\n",
    "\n",
    "def trend_function_hst(dictionary, c1, c2, c3):\n",
    "    return (1.0 \n",
    "            - c1 * (dictionary['time'] - min(dictionary['time']))\n",
    "            - c2 * np.exp(- (10**c3) * dictionary['ophase'])\n",
    "           )\n",
    "\n",
    "data_hst['trend_function'] = trend_function_hst\n",
    "\n",
    "trend_parameters_hst = [\n",
    "    [0.01, -1, 1, 'ls', '$l_s$'],\n",
    "    [0.01, -1, 1, 'sa', '$s_a$'],\n",
    "    [2, 0, 5, 'sd', '$s_d$'],\n",
    "]\n",
    "\n",
    "data_hst['trend_parameters'] = trend_parameters_hst\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "##### Define the stellar model\n",
    "###############################################################################################\n",
    "\n",
    "# Here we will combine all the stellar models from the previous notebooks.\n",
    "\n",
    "# Keep the default 'Pheonix_2018' models for all the datasets, except for the JWST.\n",
    "\n",
    "data_jwst['stellar_model'] = 'Stagger_2018'\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "##### Add observation to the Planet object\n",
    "###############################################################################################\n",
    "\n",
    "# Then we are going to add the observation to the Planet object.\n",
    "# It is advised to use planet.clear_observations() before, \n",
    "# to avoid duplications, in case we forget that we have already added the same observation.\n",
    "\n",
    "planet.clear_observations()\n",
    "planet.add_observation_from_dict(data_jwst)\n",
    "planet.add_observation_from_dict(data_hst)\n",
    "planet.add_observation_from_dict(data_tess)\n",
    "planet.add_observation_from_dict(data_ground)\n",
    "\n",
    "###############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72560cbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already here...  teff5000.0_logg4.0_MH-0.5.pickle\n",
      "File already here...  teff5000.0_logg4.0_MH0.0.pickle\n",
      "File already here...  teff5000.0_logg4.5_MH-1.0.pickle\n",
      "File already here...  teff5500.0_logg4.0_MH-0.5.pickle\n",
      "File already here...  teff5500.0_logg4.0_MH0.0.pickle\n",
      "File already here...  teff5500.0_logg4.5_MH-0.5.pickle\n",
      "File already here...  teff5500.0_logg4.5_MH0.0.pickle\n",
      "File already here...  teff5000.0_logg4.5_MH0.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "PHOENIX models are only computed for solar metallicity stars. Setting stellar_metallicity = 0.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already here...  teff05400_logg4.00_MH0.0.pickle\n",
      "File already here...  teff05400_logg4.50_MH0.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "PHOENIX models are only computed for solar metallicity stars. Setting stellar_metallicity = 0.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already here...  teff05400_logg4.00_MH0.0.pickle\n",
      "File already here...  teff05400_logg4.50_MH0.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "PHOENIX models are only computed for solar metallicity stars. Setting stellar_metallicity = 0.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already here...  teff05400_logg4.00_MH0.0.pickle\n",
      "File already here...  teff05400_logg4.50_MH0.0.pickle\n",
      "\n",
      "Observation:  obs0\n",
      "Filter:  jwst_niriss1:8600.0-28000.0\n",
      "Epoch:  715\n",
      "Data-points excluded:  0\n",
      "Scaling uncertainties by:  1\n",
      "\n",
      "Observation:  obs1\n",
      "Filter:  hst_wfc3_ir_g141:10880.0-16800.0\n",
      "Epoch:  183\n",
      "Data-points excluded:  0\n",
      "Scaling uncertainties by:  1\n",
      "\n",
      "Observation:  obs2\n",
      "Filter:  TESS\n",
      "Epoch:  694\n",
      "Data-points excluded:  0\n",
      "Scaling uncertainties by:  1\n",
      "\n",
      "Observation:  obs3\n",
      "Filter:  luminance\n",
      "Epoch:  603\n",
      "Data-points excluded:  0\n",
      "Scaling uncertainties by:  1\n",
      "\n",
      "Optimising initial parameters...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################################\n",
    "##### Test the performance of the trend function \n",
    "###############################################################################################\n",
    "\n",
    "# We can test the performance of the trend function with quick fit, using: \n",
    "# optimiser = 'curve_fit'.\n",
    "# Here, the quality of the data is good enough to fit for the orbital parameters (sma and i):\n",
    "# fit_sma_over_rs = True\n",
    "# fit_inclination = True.\n",
    "\n",
    "test = planet.transit_fitting(\n",
    "    optimiser = 'curve_fit',\n",
    "    fit_sma_over_rs=True, \n",
    "    fit_inclination=True,\n",
    ")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "##### Evaluate test results\n",
    "###############################################################################################\n",
    "\n",
    "# To evaluate the test results we can plot the raw data, trend function, and residuals like this:\n",
    "\n",
    "observations = len(test['observations'])\n",
    "plt.figure(figsize=(9,6))\n",
    "for obs_n, obs_id in enumerate(test['observations']):\n",
    "    observation = test['observations'][obs_id]\n",
    "    plt.subplot(2, observations, obs_n + 1)\n",
    "    plt.errorbar(observation['input_series']['time'], \n",
    "                 observation['input_series']['flux'], \n",
    "                 observation['input_series']['flux_unc'], \n",
    "                 fmt='o', zorder=0, label='raw data')\n",
    "    plt.plot(observation['input_series']['time'], observation['output_series']['trend'], 'r--', zorder=1, \n",
    "             label='trend model')\n",
    "    plt.plot(observation['input_series']['time'], observation['output_series']['model'], 'r-', zorder=1,\n",
    "             label='trend + transit model'\n",
    "            )\n",
    "    if obs_n == 0:\n",
    "        plt.ylabel('rel. flux')\n",
    "    plt.title(obs_id)\n",
    "\n",
    "    plt.subplot(2, observations, observations + obs_n + 1)\n",
    "    plt.errorbar(observation['input_series']['time'], \n",
    "                 observation['output_series']['residuals'], \n",
    "                 observation['input_series']['flux_unc'], \n",
    "                 fmt='o', zorder=0)\n",
    "    if obs_n == 0:\n",
    "        plt.ylabel('rel. flux residuals')\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.2)\n",
    "\n",
    "    \n",
    "    \n",
    "# And also print the residuals diagnostics like this:\n",
    "\n",
    "for obs_n, obs_id in enumerate(test['observations']):\n",
    "    observation = test['observations'][obs_id]\n",
    "    print('')\n",
    "    print('Observation: ', obs_id)\n",
    "    print('Filter: ', observation['model_info']['filter_id'])\n",
    "    print('Epoch: ', observation['model_info']['epoch'])\n",
    "    print('Number of outliers removed: ', observation['data_conversion_info']['outliers'])\n",
    "    print('Uncertainties scale factor: ', observation['data_conversion_info']['scale_factor'])\n",
    "\n",
    "    print('Residuals statistics:')\n",
    "    print('res_max_autocorr:', '\\t', observation['statistics']['res_max_autocorr'])\n",
    "    print('res_max_autocorr_flag:', '\\t', observation['statistics']['res_max_autocorr_flag'])\n",
    "    print('res_shapiro:', '\\t\\t', observation['statistics']['res_shapiro'])\n",
    "    print('res_shapiro_flag:', '\\t', observation['statistics']['res_shapiro_flag'])\n",
    "    print('res_mean:', '\\t\\t', observation['statistics']['res_mean'])\n",
    "    print('res_std:', '\\t\\t', observation['statistics']['res_std'])\n",
    "    print('res_rms:', '\\t\\t', observation['statistics']['res_rms'])\n",
    "    print('res_chi_sqr:', '\\t\\t', observation['statistics']['res_chi_sqr'])\n",
    "    print('res_red_chi_sqr:', '\\t', observation['statistics']['res_red_chi_sqr'])\n",
    "    \n",
    "###############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ae6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################################\n",
    "##### MCMC fit\n",
    "###############################################################################################\n",
    "\n",
    "# If the residuals diagniostics look ok, we can run the MCMC.\n",
    "# Here we will define the 'output_folder', so that all the results and plots are saved.\n",
    "# We don't need to defile the optimiser, as the default one is 'mcmc'.\n",
    "# It is also better to use filter_outliers=True to clear the outliers and \n",
    "# and scale_uncertainties=True to scale the errorbars to match the residuals rms.\n",
    "\n",
    "final = planet.transit_fitting(\n",
    "    output_folder = 'wasp39b_comb',\n",
    "    fit_sma_over_rs=True, \n",
    "    fit_inclination=True,\n",
    "    filter_outliers=True,\n",
    "    scale_uncertainties=True,\n",
    ")\n",
    "\n",
    "# By default, the number of iterations is 5000 and the burn in is 1000.\n",
    "# If the chains do not converge, we can increase these number, for example by setting:\n",
    "# iterations = 10000\n",
    "# burn_in = 5000\n",
    "\n",
    "###############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03acb94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
